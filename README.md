# Lab2
## Теоретичні запитання

### 1.	Що таке власне значення і власний вектор матриці? Як вони обчислюються?
Власне значення (eigenvalue) матриці A - це скаляр λ, при якому існує ненульовий вектор v (власний вектор), такий що:
Av=λv
Власний вектор (eigenvector) матриці A - це ненульовий вектор v, який змінюється лише на скаляр (власне значення) при множенні на матрицю A.

#### Обчислення власних значень і власних векторів:
- Знайдіть поліном матриці A: det⁡(A−λI)=0, де I - одинична матриця тієї ж розмірності, що й A, і λ - скаляр.
- Розв'язати рівняння для знаходження власних значень λ1, λ2 і тд.
- Для кожного знайденого власного значення λ, підставте його в рівняння (A−λI)v=0 і знайдіть відповідний власний вектор v.

### 2.	Які властивості мають власні вектори симетричних матриць?
Симетричні матриці, які задовольняють умові A=A^T, мають наступні властивості щодо власних векторів:

Ортогональність: Власні вектори, що відповідають різним власним значенням, є ортогональними.
Реальність власних значень: Всі власні значення симетричної матриці є дійсними числами.
Повний набір ортогональних власних векторів: Симетрична матриця може бути діагоналізована за допомогою ортогональної матриці, тобто її власні вектори утворюють базис, в якому матриця стає діагональною.

### 3.	Які можуть бути недоліки використання PCA, і які стратегії можуть використовуватися для подолання цих недоліків?
Лінійність: PCA може виявити тільки лінійні кореляції між змінними. Якщо дані мають нелінійні зв'язки, PCA буде неефективною.
- Стратегія: Використання нелінійних методів зменшення розмірності, таких як Kernel PCA або t-SNE.
Чутливість до масштабування: PCA чутлива до масштабу змінних. Змінні з більшими дисперсіями можуть домінувати в головних компонентах.
- Стратегія: Нормалізація або стандартизація даних перед застосуванням PCA.
Інтерпретація компонентів: Інтерпретація головних компонентів може бути складною, оскільки вони є лінійними комбінаціями початкових змінних.
- Стратегія: Аналіз вагових коефіцієнтів (loading) компонентів для кращого розуміння, які змінні найбільше впливають на компоненти.
Чутливість до шуму: PCA може бути чутливим до шуму, оскільки шум може вплинути на дисперсію даних.
- Стратегія: Використання попередньої обробки даних для фільтрації шуму або використання методів робастного PCA.

### 4.	Які переваги має діагоналізація матриці в криптографії? Як вона застосовується для шифрування та дешифрування повідомлень?
Переваги діагоналізації матриці в криптографії:

Спрощення обчислень: Діагоналізація перетворює матрицю в діагональну форму, що спрощує піднесення до степеня і множення, оскільки операції з діагональними матрицями є простішими
Розподіл власних значень: Власні значення діагональної матриці легко піддаються аналізу, що може бути корисним для розуміння структури криптографічної системи.

Застосування для шифрування та дешифрування:

    Шифрування:
        Нехай A — це матриця, що представляє криптографічний алгоритм.
        Діагоналізація матриці A: A=PDP−1, де D — діагональна матриця, P — матриця власних векторів.
        Повідомлення M шифрується як C=AMP, де C — зашифроване повідомлення, а PP забезпечує зміну базису.

    Дешифрування:
        Використовується обернена трансформація: M=P−1DC.
        Оскільки D — діагональна матриця, множення і обернене множення є простішими і менш обчислювально затратними.
